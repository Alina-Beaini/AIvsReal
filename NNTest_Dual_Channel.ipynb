{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc0f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DIM = 256\n",
    "Y_DIM = 256\n",
    "UNPROCESSED_DIRECTORY = \"CNN_synth_testset\"\n",
    "PROCESSED_DIRECTORY = \"processed_images\"\n",
    "CROP = False\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image as im_lib\n",
    "from PIL import ImageFilter\n",
    "from scipy.fftpack import dct\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Layer, Input, concatenate, MaxPooling2D, Conv2D, Dense, Dropout, Flatten\n",
    "from keras import models, Model\n",
    "from keras import layers\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import plot_model\n",
    "from keras.metrics import Metric\n",
    "import keras.backend as backend\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816444b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_image_paths(unprocessed_directory = UNPROCESSED_DIRECTORY):\n",
    "    data_directory = os.listdir(\"./\"+unprocessed_directory)\n",
    "    list_of_image_paths = []\n",
    "    for dirpath, dirname, filename in os.walk(\"./\"+unprocessed_directory):\n",
    "        if not dirname:\n",
    "            for dirpath2, dirname2, filename2 in os.walk(dirpath):\n",
    "                for filedir in filename2:\n",
    "                    list_of_image_paths.append(dirpath+\"/\"+filedir)\n",
    "    return list_of_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728fdc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create constants and import libraries\n",
    "def categorical_output(image_path):\n",
    "    keywords = [\"biggan\", \"crn\", \"cyclegan\",\"deepfake\",\"gaugan\",\"imle\",\"progan\",\"san\",\"seeingdark\",\"stargan\",\"stylegan2\", \"stylegan\",\n",
    "           \"whichfaceisreal\"]\n",
    "    category = [0] * (len(keywords) + 1)\n",
    "    for kwd_index in range(len(keywords)):\n",
    "        kwd = keywords[kwd_index]\n",
    "        if kwd in image_path:\n",
    "            category[kwd_index] = 1\n",
    "            return category\n",
    "    category[-1] = 1\n",
    "    return category\n",
    "class ImageBatchSequence(Sequence):\n",
    "    def __init__(self, x_set, batch_size, filter_functions=None, x_dim = X_DIM, y_dim = Y_DIM, \n",
    "                 output_function = None):\n",
    "        self.x = x_set\n",
    "        if output_function is None:\n",
    "            y_set = [(1 if \"fake\" in image_path else 0) for image_path in x_set] #This makes the output to be 1 (AI-generated) if FAKE is in pathname.\n",
    "            #                                                  # Otherwise, it makes the output 0 (not AI-generated)\n",
    "        else:\n",
    "            y_set = [output_function(image_path) for image_path in x_set]\n",
    "        self.y = y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.filter_functions = filter_functions #each filter function should return a normalized array\n",
    "    def __len__(self):\n",
    "        return ceil(len(self.x)/self.batch_size)\n",
    "    def __getitem__(self, index):\n",
    "        low = index * self.batch_size\n",
    "        high = min(low+self.batch_size, len(self.x))\n",
    "        batch_x = self.x[low : high]\n",
    "        batch_y = self.y[low : high]\n",
    "        if self.filter_functions is None:\n",
    "            image_x_batches = [np.array([normalize_image(image_path) for image_path in batch_x])]\n",
    "        else:\n",
    "            image_x_batches = [np.array([f(im_lib.open(image_path)) for image_path in batch_x]) for f in self.filter_functions]\n",
    "        return image_x_batches, [np.array(batch_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de081573",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = obtain_image_paths(PROCESSED_DIRECTORY)\n",
    "y = [categorical_output(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42776dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                       shuffle = True,\n",
    "                                                       random_state = 440,\n",
    "                                                       test_size = .2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aed087db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biggan:1600\n",
      "crn:5106\n",
      "cyclegan:1057\n",
      "deepfake:4324\n",
      "gaugan:4000\n",
      "imle:5105\n",
      "progan:3200\n",
      "san:174\n",
      "seeingdark:144\n",
      "stargan:1599\n",
      "stylegan:4793\n",
      "stylegan2:6390\n",
      "whichfaceisreal:800\n",
      "real : 33960\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "biggan:400\n",
      "crn:1276\n",
      "cyclegan:264\n",
      "deepfake:1081\n",
      "gaugan:1000\n",
      "imle:1277\n",
      "progan:800\n",
      "san:43\n",
      "seeingdark:36\n",
      "stargan:400\n",
      "stylegan:1198\n",
      "stylegan2:1598\n",
      "whichfaceisreal:200\n",
      "real : 8490\n"
     ]
    }
   ],
   "source": [
    "keywords = [\"biggan\", \"crn\", \"cyclegan\",\"deepfake\",\"gaugan\",\"imle\",\"progan\",\"san\",\"seeingdark\",\"stargan\", \"stylegan\",\n",
    "           \"stylegan2\",\"whichfaceisreal\"]\n",
    "for kwd in keywords:\n",
    "    print(kwd+\":\"+str(y_train.count(categorical_output(kwd))))\n",
    "print(\"real : \"+str(y_train.count(categorical_output(\"fuck\"))))\n",
    "print(\";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\")\n",
    "for kwd in keywords:\n",
    "    print(kwd+\":\"+str(y_test.count(categorical_output(kwd))))\n",
    "print(\"real : \"+str(y_test.count(categorical_output(\"fuck\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633968b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train,X_val,y_train_train,y_val = train_test_split(X_train, y_train,\n",
    "                                                          test_size=.2,\n",
    "                                                          shuffle=True,\n",
    "                                                          stratify=y_train,\n",
    "                                                          random_state=440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1827e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 254, 254, 32)         320       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 254, 254, 32)         896       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 32)         0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 127, 127, 32)         0         ['conv2d_2[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)         18496     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 125, 125, 64)         18496     ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)           0         ['conv2d_1[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 62, 62, 64)           0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 62, 62, 128)          0         ['max_pooling2d_1[0][0]',     \n",
      "                                                                     'max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 492032)               0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   3149011   ['flatten[0][0]']             \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 14)                   910       ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31529230 (120.27 MB)\n",
      "Trainable params: 31529230 (120.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#HPF Filter\n",
    "#hpf_input = Input(shape=(256,256,3))\n",
    "#hpf_1 = Conv2D(filters=32,kernel_size=(3,3),activation='relu')(hpf_input)\n",
    "#hpf_2 = MaxPooling2D(pool_size=(2,2),strides=2)(hpf_1)\n",
    "#hpf_3 = Conv2D(filters=64,kernel_size=(3,3),activation='relu')(hpf_2)\n",
    "#hpf_4 = MaxPooling2D(pool_size=(2,2),strides=2)(hpf_3)\n",
    "\n",
    "gdct_input = Input(shape=(256,256,1))\n",
    "gdct_1 = Conv2D(filters=32,kernel_size=(3,3),activation='relu')(gdct_input)\n",
    "gdct_2 = MaxPooling2D(pool_size=(2,2),strides=2)(gdct_1)\n",
    "gdct_3 = Conv2D(filters=64,kernel_size=(3,3),activation='relu')(gdct_2)\n",
    "gdct_4 = MaxPooling2D(pool_size=(2,2),strides=2)(gdct_3)\n",
    "\n",
    "#highpass filter\n",
    "highpass_input = Input(shape=(256,256,3))\n",
    "highpass_1 = Conv2D(filters=32,kernel_size=(3,3),activation='relu')(highpass_input)\n",
    "highpass_2 = MaxPooling2D(pool_size=(2,2),strides=2)(highpass_1)\n",
    "highpass_3 = Conv2D(filters=64,kernel_size=(3,3),activation='relu')(highpass_2)\n",
    "highpass_4 = MaxPooling2D(pool_size=(2,2),strides=2)(highpass_3)\n",
    "\n",
    "\n",
    "merged_1 = concatenate([gdct_4, highpass_4])\n",
    "merged_2 = Flatten()(merged_1)\n",
    "merged_3 = Dense(units=64, activation='relu')(merged_2)\n",
    "multiclass= Dense(units=14, activation = 'softmax')(merged_3)\n",
    "#binary = Dense(units=1,activation='softmax')(merged_3)\n",
    "\n",
    "model = Model(inputs = [gdct_input,highpass_input], outputs = multiclass)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "#plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "352c06a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassPrecisionMetric(Metric):\n",
    "    def __init__(self, name = \"mp\", category_tested = 0):\n",
    "        super(MulticlassPrecisionMetric,self).__init__(name = name)\n",
    "        self.category_tested = category_tested\n",
    "        self.multi_true_positives = self.add_weight(name = 'tp' + str(self.category_tested), initializer = 'zeros')\n",
    "        self.multi_tf_positives = self.add_weight(name = 'tfp' + str(self.category_tested), initializer = 'zeros')\n",
    "        self.mp = self.add_weight(name = 'mp' + str(self.category_tested), initializer = 'zeros')\n",
    "    def update_state(self, y_true, y_pred, sample_weight = None):\n",
    "        y_true = tf.argmax(y_true, axis = -1)\n",
    "        y_pred = tf.argmax(y_pred, axis = -1)\n",
    "        tp = tf.reduce_sum(\\\n",
    "                         tf.cast(tf.equal(y_true,self.category_tested),tf.float32)\\\n",
    "                         *tf.cast(tf.equal(y_pred,self.category_tested),tf.float32))\n",
    "        self.multi_true_positives.assign_add(tp)\n",
    "        self.multi_tf_positives.assign_add(\\\n",
    "                                           tf.reduce_sum(\\\n",
    "                                                       tf.cast(tf.equal(y_pred,self.category_tested),tf.float32)))\n",
    "        self.mp.assign(self.multi_true_positives/(self.multi_tf_positives+backend.epsilon()))\n",
    "    def result(self):\n",
    "        return self.mp\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fdf2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassRecallMetric(Metric):\n",
    "    def __init__(self, name = \"mp\", category_tested = 0):\n",
    "        super(MulticlassRecallMetric,self).__init__(name = name)\n",
    "        self.category_tested = category_tested\n",
    "        self.multi_true_positives = self.add_weight(name = 'tp' + str(self.category_tested), initializer = 'zeros')\n",
    "        self.multi_predic = self.add_weight(name = 'tpr' + str(self.category_tested), initializer = 'zeros')\n",
    "        self.mr = self.add_weight(name = 'mr' + str(self.category_tested), initializer = 'zeros')\n",
    "    def update_state(self, y_true, y_pred,sample_weight = None):\n",
    "        y_true = tf.argmax(y_true, axis = -1)\n",
    "        y_pred = tf.argmax(y_pred, axis = -1)\n",
    "        tp = tf.reduce_sum(\\\n",
    "                         tf.cast(tf.equal(y_true,self.category_tested),tf.float32)\\\n",
    "                         *tf.cast(tf.equal(y_pred,self.category_tested),tf.float32))\n",
    "        self.multi_true_positives.assign_add(tp)\n",
    "        self.multi_predic.assign_add(\\\n",
    "                                           tf.reduce_sum(\\\n",
    "                                                       tf.cast(tf.equal(y_true,self.category_tested),tf.float32)))\n",
    "        self.mr.assign(self.multi_true_positives/(self.multi_predic+backend.epsilon()))\n",
    "    def result(self):\n",
    "        return self.mr\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e44548fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"biggan\", \"crn\", \"cyclegan\",\"deepfake\",\"gaugan\",\"imle\",\"progan\",\"san\",\"seeingdark\",\"stargan\",\"stylegan2\",\n",
    "            \"stylegan\", \"whichfaceisreal\"]\n",
    "METRICS = []\n",
    "for kwd_index in range(len(keywords)):\n",
    "    precision_metric = MulticlassPrecisionMetric(name = \"precision_\"+keywords[kwd_index], \n",
    "                                                 category_tested = kwd_index)\n",
    "    recall_metric = MulticlassRecallMetric(name = \"recall_\"+keywords[kwd_index], \n",
    "                                                 category_tested = kwd_index)\n",
    "    METRICS.append(precision_metric)\n",
    "    METRICS.append(recall_metric)\n",
    "precision_metric = MulticlassPrecisionMetric(name = \"precision_real\", category_tested = len(keywords))\n",
    "recall_metric = MulticlassRecallMetric(name = \"recall_real\", category_tested = len(keywords))\n",
    "METRICS.append(precision_metric)\n",
    "METRICS.append(recall_metric)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics = [METRICS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c9bfd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image,normalizing_factor=255):\n",
    "    if image.mode == 'RGB':\n",
    "        return np.asarray(image).reshape(image.size[0],image.size[1],3)/normalizing_factor\n",
    "    if image.mode == 'L':\n",
    "        return np.assarray(image)/normalizing_factor\n",
    "\n",
    "def HPF_filter(image):\n",
    "    return normalize_image(im_lib.fromarray(np.asarray(image)-np.asarray(image.filter(ImageFilter.GaussianBlur))))\n",
    "\n",
    "#combines the filters for each color channel as one image\n",
    "def highpassrgb(image):\n",
    "    red, green, blue = image.split()\n",
    "    return normalize_image(im_lib.merge(mode='RGB',bands=(red.filter(ImageFilter.Kernel((3,3),(0,-1,0,-1,4,-1,0,-1,0),1,0)), green.filter(ImageFilter.Kernel((3,3),(0,-1,0,-1,4,-1,0,-1,0),1,0)), blue.filter(ImageFilter.Kernel((3,3),(0,-1,0,-1,4,-1,0,-1,0),1,0)))))\n",
    "\n",
    "#grayscale discrete cosine transform\n",
    "def gdct(image):\n",
    "    a = np.array(image.convert('L'))\n",
    "    return dct(dct(a.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "\n",
    "\n",
    "#log-scaled and normalized gdct\n",
    "def normalized_gdct(image):\n",
    "    array = gdct(image)\n",
    "    sgn = np.sign(array)\n",
    "    logscale = sgn*np.log(abs(array)+0.000000001) #symmetric log scale, shifted slightly to be defined at 0\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(array)\n",
    "    return scaler.transform(logscale)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c2e98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = ImageBatchSequence(X_train_train, batch_size = 32, filter_functions= [normalized_gdct, highpassrgb], \n",
    "                                    output_function = categorical_output)\n",
    "validation_sequence = ImageBatchSequence(X_val, batch_size = 32, filter_functions= [normalized_gdct, highpassrgb],\n",
    "                                    output_function = categorical_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa0f0e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch_count = 20\n",
    "history = model.fit(train_sequence, epochs = epoch_count, validation_data = validation_sequence)\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "model.save(\"dual_channel_model\")\n",
    "model.save_weights(\"dual_channel_model_best_val_real_precision_weights\")\n",
    "np.save(\"my_history.npy\",history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fbc84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for kwd in keywords:\n",
    "    training_kwd_precision = \"precision_\" + kwd\n",
    "    training_kwd_recall = \"recall_\" + kwd\n",
    "    validation_kwd_precision = \"val_precision_\" + kwd\n",
    "    validation_kwd_recall = \"val_recall_\" + kwd\n",
    "    plt.figure(figsize = (8,6))\n",
    "    plt.plot(range(1,epoch_count + 1), history_dict[training_kwd_precision], label = \"Training \" +kwd+ \" Precision\")\n",
    "    plt.plot(range(1,epoch_count + 1), history_dict[training_kwd_recall], label = \"Training \" +kwd+ \" Recall\")\n",
    "    plt.plot(range(1,epoch_count + 1), history_dict[validation_kwd_precision], label = \"Validation \" +kwd+ \" Precision\")\n",
    "    plt.plot(range(1,epoch_count + 1), history_dict[validation_kwd_recall], label = \"Validation \" +kwd+ \" Recall\")\n",
    "    plt.legend(fontsize = 10)\n",
    "    plt.savefig(kwd+'.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(range(1,epoch_count + 1), history_dict[\"precision_real\"], label = \"Training Real Precision\")\n",
    "plt.plot(range(1,epoch_count + 1), history_dict[\"recall_real\"], label = \"Training Real Recall\")\n",
    "plt.plot(range(1,epoch_count + 1), history_dict[\"val_precision_real\"], label = \"Validation Real Precision\")\n",
    "plt.plot(range(1,epoch_count + 1), history_dict[\"val_recall_real\"], label = \"Validation Real Recall\")\n",
    "plt.legend(fontsize = 10)\n",
    "plt.savefig(kwd+'.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e7f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
